{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef39ed18",
   "metadata": {},
   "source": [
    "# Levenshtein Distance for searchbar functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78053a0",
   "metadata": {},
   "source": [
    "A situation may occur in the searchbar where the user of the website may type their text incorrectly. Due to the nature of not having a spelling check for the reader (where a red underline is under the incorrectly spelled word(s)), this may make the reader confused when searching for an item and it doesnt exist.\n",
    "\n",
    "Regex is the natural tool to solve most of these issues, however it cannot directly solve issues of incorrect spelling (at least not easily).\n",
    "\n",
    "The Levenshtein distance is used to create a comparison score between 2 strings. The score can be described as the minimal amount of changes including insertions, reorders and deletions used to convert the first string into the desired string (string 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a27f1a",
   "metadata": {},
   "source": [
    "This can be characterized by the following formula which will be explained below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01abc4a7",
   "metadata": {},
   "source": [
    "$$\n",
    "Lev(a, b) = |a|, \\text{if}  |b| = 0, \\newline\n",
    "            |b|, \\text{if}  |a| = 0, \\newline\n",
    "            |b|, \\text{if}  |a| = 0, \\newline\n",
    "            Lev(a[1:], b[1:]) \\text{if} a[0] = b[0], \\newline\n",
    "            1 + \\min{\n",
    "                    Lev(a[1:], b) \\newline\n",
    "                    Lev(a, b[1:]) \\newline\n",
    "                    Lev(a[1:], b[1:]) \\newline\n",
    "                    }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40ab09a",
   "metadata": {},
   "source": [
    "We note that this can be quite expensive due to the recursiveness of the algorithim however using dynamic programming techniques we can reduce the amount of recursive iterations in the program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a85b9f",
   "metadata": {},
   "source": [
    "We note that with this in mind we have a simplified time complexity of O(n**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78af23bc",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4534a7ce",
   "metadata": {},
   "source": [
    "Although we can program this partitioned problem manually, Python already comes with a library which can decide this: FuzzyWuzzy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9c281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def stringComp(x, y):\n",
    "    return fuzz.token_sort_ratio(x, y)\n",
    "    #sort first\n",
    "    #compute levenshtein distance for each string\n",
    "\n",
    "\n",
    "\n",
    "def testcases():\n",
    "    list = [\n",
    "        ['canola oil', 'oil canola'],\n",
    "        ['canola oil', 'canola oil'],\n",
    "        ['canola oil', 'canolaoil'],\n",
    "        ['oil of canola', 'canola oil'],\n",
    "        ['CanolaOIL', 'CANOLAoil'],\n",
    "        ['CANOLA oil', 'canola OIL'],\n",
    "        ['', '']\n",
    "        ]\n",
    "\n",
    "    for i in range(len(list)):\n",
    "        print(stringComp(list[i][0], list[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "935f9e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "95\n",
      "87\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "testcases()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2fb523",
   "metadata": {},
   "source": [
    "As can be seen from the results above, after each iteration, we return a score where string 1 is x% like string y. Now a consideration is due to the size of the excel file we are using, an O(n^2) algorithim for > 3000 records may be issuous when it comes to a search bar functionality where the key task is time.\n",
    "\n",
    "Below if a function which reads all product titles and returns the scores from a given input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b430fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openpyxl\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_xl():\n",
    "    df = pd.read_excel('FoldedRegions.xlsx')\n",
    "    return df['Product Names'].values.tolist()\n",
    "\n",
    "def compute_lev_on_dataset(input_str):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    lst = read_xl()\n",
    "\n",
    "    for i in range(len(lst)):\n",
    "        stringComp(input_str, lst[i])\n",
    "        \n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    return elapsed_time\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1799a896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.372722864151001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_lev_on_dataset('Canola Oil')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a869fcda",
   "metadata": {},
   "source": [
    "Interestingly enough we note that even with reading the list and then computing the levenstein distance we have an elapsed time of ~1.4 seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6769a417",
   "metadata": {},
   "source": [
    "# Concluding remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd916fb",
   "metadata": {},
   "source": [
    "This feature may be quite helpful if a given score is deemed acceptable. For example, as the regex developed cannot handle incorrect spellings (in our implementation) we can have some kind of logic, where if the returned list of items is < x where x is some natural number, we can consider using the levenstein distance.\n",
    "\n",
    "The of course will only work if the spelling of the word is somewhat accurate. For example, if we had decided to use 'HelloWorld' and the user input was 'w05l4H3llo0' this would likley yield our accuracy score useless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5769bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
